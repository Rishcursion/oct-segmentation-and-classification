{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5da78b9-d13d-4d56-9e2b-194d41859e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding sibling directory to path of current directory\n",
    "import sys\n",
    "import os\n",
    "# Adding Dataset to import path\n",
    "sibling_dir = \"../dataset\"\n",
    "sys.path.insert(1, sibling_dir)\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bbb27-f3ac-45d6-b2f1-ed4a89773110",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Of Segmentation And Classification Data Of OCT Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede4cd9e-db80-4760-8b4b-12f531aa394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30ee43-4afd-410d-a7e2-6b15d534403b",
   "metadata": {},
   "source": [
    "## 1. Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b030bd-b00b-482a-8948-683285bc9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the classification data splits\n",
    "from collections import defaultdict\n",
    "\n",
    "from classificationData import classificationData\n",
    "\n",
    "class_val = classificationData(\"val\", None)\n",
    "class_train = classificationData(\"train\", None)\n",
    "class_test = classificationData(\"test\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7f5e09-f93e-42d0-a1e7-528e88a51159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels: ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Labels: {class_train.classes}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101b670-aaf0-4d57-98ff-8e5e8c249359",
   "metadata": {},
   "source": [
    "## 1.1 Subset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d126b122-aea9-4fd8-b63e-4b133ee8ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_dist = go.Figure(go.Bar(x=[\"Test\",\"Train\",\"Validation\"], y=[len(class_test), len(class_train), len(class_val)]))\n",
    "class_dist.update_layout(title_text=\"Distribution Of Images Across Subsets\")\n",
    "class_dist.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04257a3-cf2c-41cd-b826-7df45720837e",
   "metadata": {},
   "source": [
    "As we can see from the above graph, The distribution has the following split:\n",
    "- Train Set ~= 70%\n",
    "- Test Set ~= 10%\n",
    "- Validation Set ~= 20%\n",
    "\n",
    "\n",
    "Thus, there is no need for modifying the distribution of the subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018642a-7146-4f53-991f-ea0e886dfb05",
   "metadata": {},
   "source": [
    "## 1.2 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21b8b1-ec74-47a9-be99-20512bda85cd",
   "metadata": {},
   "source": [
    "### 1.2.1 Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2f3855-97a3-4e93-bd70-1eeb94d1946f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = dict(enumerate(class_train.classes))\n",
    "class_train_counts = defaultdict(int)\n",
    "for _, label in class_train.labels.items():\n",
    "    class_train_counts[labels[label]]+=1\n",
    "class_train_dist = go.Figure(go.Bar(y=list(class_train_counts.values()), x=list(class_train_counts.keys())))\n",
    "class_train_dist.update_layout(title_text = \"Class Distribution In Train Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f1bc7-e772-46e6-be81-126326e3be27",
   "metadata": {},
   "source": [
    "### 1.2.2 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572156ce-3bb2-435e-b48a-ffcadf8ec781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = dict(enumerate(class_train.classes))\n",
    "class_test_counts = defaultdict(int)\n",
    "for _, label in class_test.labels.items():\n",
    "    class_test_counts[labels[label]]+=1\n",
    "class_test_dist = go.Figure(go.Bar(y=list(class_test_counts.values()), x=list(class_test_counts.keys())))\n",
    "class_test_dist.update_layout(title_text = \"Class Distribution In Test Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44528060-5165-4053-b7c4-7481d4837207",
   "metadata": {},
   "source": [
    "### 1.2.3 Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618a0a3e-7cf2-4285-b465-1d2cc867740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = dict(enumerate(class_val.classes))\n",
    "class_val_counts = defaultdict(int)\n",
    "for _, label in class_val.labels.items():\n",
    "    class_val_counts[labels[label]]+=1\n",
    "class_val_dist = go.Figure(go.Bar(y=list(class_val_counts.values()), x=list(class_val_counts.keys())))\n",
    "class_val_dist.update_layout(title_text = \"Class Distribution In Validation Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83b74a-5737-4a5d-9521-b730d5a34b78",
   "metadata": {},
   "source": [
    "__As we can see from the above histograms, we can see that the proportion of images across classes remain the same, which can be verified by calculating the percentages for each class. Therefore, we conclude that the dataset splits are valid and do not need any further modification__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6a56c-a837-40bd-92fd-819f492cf3ac",
   "metadata": {},
   "source": [
    "## 1.3 Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ccbe4d-4be9-45d4-b1e1-5d183cbd5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = {}\n",
    "val_images = {}\n",
    "test_images = {}\n",
    "# Iterate over datasets and select one image per class\n",
    "for dataset, target_dict in zip([class_train, class_val, class_test], \n",
    "                                [train_images, val_images, test_images]):\n",
    "    seen_classes = set()  # Track which classes have been added\n",
    "\n",
    "    for img_path, label in dataset.labels.items():\n",
    "        if label not in seen_classes:  # If class is not already in the dictionary\n",
    "            target_dict[label] = img_path\n",
    "            seen_classes.add(label)  # Mark class as seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fdf807-1691-4e9c-b207-03dcd4252d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_10.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine selected images from train, val, and test sets\n",
    "all_selected_images = list(train_images.items()) + list(val_images.items()) + list(test_images.items())\n",
    "\n",
    "# Create a 4x4 subplot grid\n",
    "fig = make_subplots(rows=4, cols=4, subplot_titles=[f\"Class {label}\" for label, _ in all_selected_images])\n",
    "\n",
    "# Iterate over selected images and add them to the grid\n",
    "for i, (label, img_path) in enumerate(all_selected_images[:16]):  # Show only 16 images\n",
    "    row = (i // 4) + 1  # Compute row index (1-based)\n",
    "    col = (i % 4) + 1   # Compute column index (1-based)\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")  # Load and convert image to RGB\n",
    "    img_array = np.array(img)  # Convert PIL image to NumPy array\n",
    "\n",
    "    # Add image trace\n",
    "    fig.add_trace(go.Image(z=img_array), row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=800, width=800, title_text=\"Sample Images From Each Class\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6353e-da57-4d49-bcb5-2d1293046b82",
   "metadata": {},
   "source": [
    "## 1.4 Final Observations:\n",
    "From the initial data exploration, we have observed that the data distribution is satisfactory regarding classes as well as subsets. We can also see that the dataset contains images with random augmentations applied such as image distortion, shearing, translation and cropping, which will help in making our classifier model more robust and improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45de2f3-02ce-4bc1-ae23-f4a1fb0a21b7",
   "metadata": {},
   "source": [
    "## 2. Segmentation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683410c2-c413-4482-94e5-8baf7832de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the segmentation data\n",
    "from segmentationData import segmentationData\n",
    "seg_data = segmentationData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee9742b-f02f-4feb-b4d1-add1a3e51533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Images: 3859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Total Images: {len(seg_data)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d13ea4a-9151-433a-bafd-b3028ea906a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1820px\"\n",
       "    height=\"1520\"\n",
       "    src=\"iframe_figures/figure_18.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select 6 images\n",
    "num_images = 6\n",
    "selected_images = list(zip(seg_data.image_paths[:num_images], seg_data.gt_paths[:num_images]))\n",
    "\n",
    "# Create a 3-row, 3-column subplot grid\n",
    "fig = make_subplots(rows=6, cols=3, \n",
    "                    subplot_titles=[\"Image\", \"Ground Truth\", \"Overlay\"] * num_images)\n",
    "\n",
    "for i, (img_path, gt_path) in enumerate(selected_images):\n",
    "    row = i + 1  # Row index (1-based)\n",
    "\n",
    "    # Load images\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    gt = Image.open(gt_path).convert(\"L\")  # Convert mask to grayscale\n",
    "\n",
    "    # Resize ground truth mask to match image size\n",
    "    gt = gt.resize(img.size, Image.NEAREST)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    img_array = np.array(img)\n",
    "    gt_array = np.array(gt)\n",
    "\n",
    "    # Normalize mask to 0-255 scale (binary mask)\n",
    "    gt_overlay = (gt_array > 128).astype(np.uint8) * 255\n",
    "\n",
    "    # Overlay: Blend image and mask\n",
    "    overlay = img_array.copy()\n",
    "    overlay[:, :, 0] = np.maximum(overlay[:, :, 0], gt_overlay)  # Red channel blend\n",
    "\n",
    "    # Add images to plotly subplots\n",
    "    fig.add_trace(go.Image(z=img_array), row=row, col=1)\n",
    "    fig.add_trace(go.Image(z=gt_array), row=row, col=2)\n",
    "    fig.add_trace(go.Image(z=overlay), row=row, col=3)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1500, width=1800, title_text=\"Segmentation Dataset Visualization\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f9767-180b-4280-925e-6392dd5030ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
